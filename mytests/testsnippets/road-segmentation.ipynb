{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import backend as keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect TPU, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "#     strategy = tf.distribute.get_strategy() \n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# batch_size =  16 * strategy.num_replicas_in_sync\n",
    "batch_size = 16\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "print(\"Batch size: \", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = y_true\n",
    "    y_pred_f = y_pred\n",
    "    intersection = tf.math.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.math.reduce_sum(y_true_f) + tf.math.reduce_sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "  intersection = tf.math.reduce_sum(tf.math.abs(y_true * y_pred), axis=[1,2,3])\n",
    "  union = tf.math.reduce_sum(y_true,[1,2,3])+tf.math.reduce_sum(y_pred,[1,2,3])-intersection\n",
    "  iou = tf.math.reduce_mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "  return iou\n",
    "\n",
    "\n",
    "def unet(input_size = (256, 256, 3)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', \n",
    "                                               kernel_initializer = 'he_normal'\n",
    "                                               )(inputs)\n",
    "    \n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', \n",
    "                                               kernel_initializer = 'he_normal'\n",
    "                                               )(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', \n",
    "                                                kernel_initializer = 'he_normal'\n",
    "                                                )(pool1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', \n",
    "                                                kernel_initializer = 'he_normal'\n",
    "                                                )(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', \n",
    "                                                kernel_initializer = 'he_normal'\n",
    "                                                )(pool2)\n",
    "    \n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same',\n",
    "                                                kernel_initializer = 'he_normal'\n",
    "                                                )(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', \n",
    "                                                kernel_initializer = 'he_normal'\n",
    "                                                )(pool3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', \n",
    "                                                kernel_initializer = 'he_normal'\n",
    "                                                )(conv4)\n",
    "    \n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', \n",
    "                                                 kernel_initializer = 'he_normal'\n",
    "                                                 )(pool4)\n",
    "    \n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', \n",
    "                                                 kernel_initializer = 'he_normal'\n",
    "                                                 )(conv5)\n",
    "    \n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', \n",
    "                                              kernel_initializer = 'he_normal'\n",
    "                                              )(UpSampling2D(size = (2,2))(drop5))\n",
    "    \n",
    "    merge6 = concatenate([drop4,up6])\n",
    "    \n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same',\n",
    "                                                kernel_initializer = 'he_normal'\n",
    "                                                )(merge6)\n",
    "    \n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same',\n",
    "                                                kernel_initializer = 'he_normal'\n",
    "                                                )(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same',\n",
    "                                              kernel_initializer = 'he_normal'\n",
    "                                              )(UpSampling2D(size = (2,2))(conv6))\n",
    "    \n",
    "    merge7 = concatenate([conv3,up7])\n",
    "    \n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same',\n",
    "                                                kernel_initializer = 'he_normal'\n",
    "                                                )(merge7)\n",
    "    \n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal'\n",
    "                                                )(conv7)\n",
    "\n",
    "    \n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same',\n",
    "                                              kernel_initializer = 'he_normal'\n",
    "                                              )(UpSampling2D(size = (2,2))(conv7))\n",
    "    \n",
    "    merge8 = concatenate([conv2,up8])\n",
    "    \n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same',\n",
    "                                                kernel_initializer = 'he_normal'\n",
    "                                                )(merge8)\n",
    "    \n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same',\n",
    "                                                kernel_initializer = 'he_normal'\n",
    "                                                )(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same',\n",
    "                                             kernel_initializer = 'he_normal'\n",
    "                                             )(UpSampling2D(size = (2,2))(conv8))\n",
    "    \n",
    "    merge9 = concatenate([conv1,up9])\n",
    "    \n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same',\n",
    "                                               kernel_initializer = 'he_normal'\n",
    "                                               )(merge9)\n",
    "    \n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same',\n",
    "                                               kernel_initializer = 'he_normal'\n",
    "                                               )(conv9)\n",
    "    \n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same',\n",
    "                                              kernel_initializer = 'he_normal'\n",
    "                                              )(conv9)\n",
    "    \n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(learning_rate = 1e-3), loss = 'binary_crossentropy', metrics = [dice_coef, iou_coef])\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*'*30)\n",
    "print('Loading and preprocessing train data...')\n",
    "print('*'*30)\n",
    "file = h5py.File('/kaggle/input/road-maps/Dataset_train.h5', 'r')\n",
    "img_train = file.get('images')\n",
    "mask_train = file.get('masks')\n",
    "img_train = np.array(img_train)\n",
    "mask_train = np.array(mask_train)\n",
    "\n",
    "img_train = img_train.astype('float32')\n",
    "img_train /= 255\n",
    "\n",
    "mask_train = mask_train.astype('float32')\n",
    "mask_train /= 255  # scale masks to [0, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet()\n",
    "print('Model compiled')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*'*30)\n",
    "print('Fitting model...')\n",
    "print('*'*30)\n",
    "\n",
    "epochs = 100\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "# model_checkpoint = ModelCheckpoint(f'weights_bceloss_{epochs}epochs.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "history =  model.fit(img_train, mask_train, batch_size=16, epochs=epochs, verbose=1, shuffle=True,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('Dataset_test.h5', 'r')\n",
    "img_test = file.get('images')\n",
    "mask_test = file.get('masks')\n",
    "img_test = np.array(img_test)\n",
    "mask_test = np.array(mask_test)\n",
    "img_test = img_test.astype('float32')\n",
    "\n",
    "img_test /= 255\n",
    "\n",
    "print('*'*30)\n",
    "print('Loading saved weights...')\n",
    "print('*'*30)\n",
    "#model.load_weights('weights.h5')\n",
    "\n",
    "print('*'*30)\n",
    "print('Predicting masks on test data...')\n",
    "print('*'*30)\n",
    "mask_pred = model.predict(img_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*' * 30)\n",
    "print('Saving predicted masks to files...')\n",
    "print('*' * 30)\n",
    "pred_dir = 'Preds2'\n",
    "if not os.path.exists(pred_dir):\n",
    "    os.mkdir(pred_dir)\n",
    "for i, image in enumerate(mask_pred):\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    cv2.imwrite(os.path.join(pred_dir, str(i + 1) + '_pred.png'), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60, 30))\n",
    "plt.plot(history.history['loss'], linewidth=8, color='r')                   #visualising training and validation loss curves\n",
    "plt.plot(history.history['val_loss'], linewidth=8, color='b')\n",
    "plt.title('Model train vs Validation Loss', fontsize=100, fontweight=\"bold\")\n",
    "plt.ylabel('Loss', fontsize=80)\n",
    "plt.xlabel('Epoch', fontsize=80)\n",
    "plt.legend(['Train', 'Validation'], loc='upper right', fontsize=50)\n",
    "plt.xticks(fontsize=60)\n",
    "plt.yticks(fontsize=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 893591,
     "sourceId": 1516242,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4738958,
     "sourceId": 8038313,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
